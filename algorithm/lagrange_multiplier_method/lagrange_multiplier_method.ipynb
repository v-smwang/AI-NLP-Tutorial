{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、从最优化引出拉格朗日数乘法\n",
    "\n",
    "## 1、一个最简单的无约束优化问题\n",
    "\n",
    "在学习与工程之中，我们时常会遇到一些优化的问题，也就是要对某个目标函数求取极值，最简单的形式如下。\n",
    "\n",
    "$$\\min_{x \\in \\mathbb{R}^{n}} f(x)$$\n",
    "\n",
    "这个式子表达的含义是以x为自变量，求取f(x)的最小值。如果想要求取最大值，可以把f加一个负号，这样把$\\max_{x}f(x)$转换为等价的$\\min_{x}-f(x)$就行了。另外需要注意的是x并非一个标量数值，而是n维实数空间上的一个向量。\n",
    "\n",
    "这样的例子有很多，最常见的就比如我们在机器学习中经常碰到的最小化代价函数。对于这样的问题，我们求解的方法很简单，只要能够求出一个点$x^{\\prime}$，使得 $\\nabla f\\left(x^{\\prime}\\right)=0$即可。\n",
    "\n",
    "当然我们也知道，只有当f是凸函数的时候，这样求出来的才是全局最优点，否则不过是个局部最优点罢了。不过这就不在我们的讨论范围内了。现在我们姑且假定讨论的f都是凸函数。\n",
    "\n",
    "## 2、带有等式约束的优化问题\n",
    "\n",
    "我们在上一节的基础上进一步，如果f是有约束的呢？\n",
    "\n",
    "$$\\min_{x \\in \\mathbb{R}^{n}} f(x)$$\n",
    "$$s.t \\quad h_{i}(x)=0, i \\in[1, l]$$\n",
    "\n",
    "在这个问题中，我们对在定义域上的x有了$l$个等式约束$h_i$。这样一来我们就不能随意的计算导数等于0的点作为最优点了。那要怎么做呢？\n",
    "\n",
    "这时就需要用到拉格朗日乘数法了，具体而言，我们首先来构建这么一个拉格朗日函数:\n",
    "\n",
    "$$L(x, \\lambda)=f(x)+\\sum_{i=1}^{l} \\lambda_{i} h_{i}(x)$$\n",
    "$$x \\in \\mathbb{R}^{n}, \\lambda \\in \\mathbb{R}^{l}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里λ是新引入的参数，被称为拉格朗日乘子，在这里它是一个$l$维的向量。\n",
    "\n",
    "接着我们需要求解方程:\n",
    "\n",
    "$$x \\in \\mathbb{R}^{n}, \\lambda \\in \\mathbb{R}^{l}$$\n",
    "\n",
    "求解出来的结果$x^\\prime$必然就是最大值或最小值对应的点，只要稍加检验就可以得出结果了。\n",
    "\n",
    "那么为什么会这样呢？这里我们稍加解释，如下图所示，f(x,y)是我们的目标函数f(x)，而g(x,y)则是我们的约束条件h(x)。\n",
    "\n",
    "<img src=\"imgs/intersection.png\" width=\"300\"/>\n",
    "\n",
    "显然我们的目标就是求出在f和g的交点上的最小值。稍加思索，我们不难发现，这样的点一定是两个g和f的某个等高线相切的一个点。原因很简单：假定我们的目标$x^*$不是切点，那么它必然可以沿着负梯度的方向朝着更低的方向前进，那这就意味着它必然不是最小值对应的点。\n",
    "\n",
    "所以我们就有结论:\n",
    "\n",
    "若$x^*$是被等式h约束的最优化问题$\\min f$的解，则f和h在$x^*$处相切。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然f和h在$x^*$上相切，那就意味着二者在这一点的梯度的方向相同，即:\n",
    "\n",
    "$$\\nabla f=\\lambda \\nabla h, \\quad \\lambda \\neq 0$$\n",
    "\n",
    "稍加整理，我们就可以得出结论，只要x满足:\n",
    "\n",
    "$$\\left\\{\\begin{array}{l}\\frac{d f}{d x}+\\lambda \\frac{d h}{d x}=0 \\\\ h(x)=0\\end{array}\\right.$$\n",
    "\n",
    "那么x就是我们希望的最优点。稍加整理就是上面的拉格朗日函数的形式了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、再加上不等式约束\n",
    "\n",
    "然而实际生活中我们可能碰到的问题比上面的还要复杂，不仅仅是有等式约束，还可能会有不等式约束。\n",
    "\n",
    "现在假定$f(x),c_i(x),h_i(x)$都是定义在$\\mathbb{R}^n$上的连续可微函数，则考虑约束最优化问题:\n",
    "\n",
    "$$\\min_{x \\in \\mathbb{R}^{n}} f(x)$$\n",
    "$$s.t \\quad c_{i}(x)\\leq 0, i \\in[1, k]$$\n",
    "$$\\quad \\quad h_{j}(x)=0, j \\in[1, l]$$\n",
    "\n",
    "这就是我们实际会遇到的优化问题的基本形式。如何求解这个优化问题也就是这篇文章主要要探讨的。\n",
    "\n",
    "关于具体如何求解，我们后面再说，先把一些需要用到的数学概念理清。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、预备的数学知识\n",
    "\n",
    "**数学符号说明**\n",
    "\n",
    "- min/max符号\n",
    "\n",
    "$$\\min _{x} f(x)$$\n",
    "\n",
    "表示求取当f(x)最小时，x的取值\n",
    "\n",
    "$$\\max _{x \\in D} f(x, \\lambda)$$\n",
    "\n",
    "表示固定变量$\\lambda$在满足x在D集合里，f(x)取最大值时，x的取值\n",
    "\n",
    "$$v=\\max _{\\lambda} \\min _{x} f(x, \\lambda)$$\n",
    "\n",
    "这个式子要从右往左看，首先把$\\min _{x} f(x, \\lambda)$这一项理解成关于λ的函数g(λ)，然后再对g求最大值，即:\n",
    "\n",
    "$$g(\\lambda)=\\min _{x} f(x, \\lambda)$$\n",
    "\n",
    "$$v=\\max _{\\lambda}g(\\lambda)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inf和sup符号\n",
    "\n",
    "inf是infimum(下确界)的简称，而sup是supremum(上确界)的简称。它们和min还有max很相似，但是细节部分略有不同。具体来讲，一个例子足以:\n",
    "\n",
    "有函数$f(x)=\\frac{sin(x)}{x}$:\n",
    "\n",
    "<img src=\"imgs/sinx_divide_x.png\" width=\"300\"/>\n",
    "\n",
    "显然f在0处没有定义。那么:\n",
    "\n",
    "$\\max{f}$不存在\n",
    "\n",
    "$\\sup{f}$存在，且为1\n",
    "\n",
    "- 其他符号\n",
    "\n",
    "$dom f$: 函数f的定义域\n",
    "\n",
    "$⋂S_i$：对若干集合$S_i$求交集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**凸函数和凹函数**\n",
    "\n",
    "<img src=\"imgs/convex_concave.png\" width=\"300\"/>\n",
    "\n",
    "没错，其实是上凹下凸，这是国际惯例，我们国内的定义(也就是中学教的)是反过来的，我们在此后一律使用国际标准。\n",
    "\n",
    "另外关于凸函数和凹函数有性质如下:\n",
    "\n",
    "1. 若函数$f:\\mathbb{R}^n \\to \\mathbb{R}$是凸的，则:\n",
    "\n",
    "$$\\forall x, y \\in \\operatorname{dom} f, \\forall \\theta \\in[0,1]$$\n",
    "\n",
    "$$\\theta f(x)+(1-\\theta) f(y) \\leq f(\\theta x+(1-\\theta) y)$$\n",
    "\n",
    "表示凸函数图像上的任意两点做连线，连线上的函数值（红色直线）都会大于被截断这段弧线（绿色弧线）上的函数值。$\\theta$就是来控制线上点的范围的。\n",
    "\n",
    "<img src=\"imgs/convex_concave_property.png\" width=\"300\"/>\n",
    "\n",
    "2. 若函数$f:\\mathbb{R}^n \\to \\mathbb{R}$是凹的，则:\n",
    "\n",
    "$$\\forall x, y \\in \\operatorname{dom} f, \\forall \\theta \\in[0,1]$$\n",
    "\n",
    "$$\\theta f(x)+(1-\\theta) f(y) \\geq f(\\theta x+(1-\\theta) y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**仿射函数**\n",
    "\n",
    "仿射函数，即最高次数为1的多项式函数。常数项为零的仿射函数称为线性函数。\n",
    "\n",
    "假设有$\\vec{x} \\in \\mathbb{R}^{n}, \\vec{b} \\in \\mathbb{R}^{m}$，矩阵$A_{m×n}$那么：\n",
    "\n",
    "$$\\vec{x} \\rightarrow A \\vec{x}+\\vec{b}$$\n",
    "\n",
    "被称为$\\mathbb{R}^n \\rightarrow \\mathbb{R}^m$的仿射变换，这一过程被称为仿射函数。\n",
    "\n",
    "$$f(x)=A x+b, x \\in \\mathbb{R}^{n}$$\n",
    "\n",
    "比如最简单的:\n",
    "\n",
    "$$a_{1} x_{1}+a_{2} x_{2}+\\cdots+a_{n} x_{n}+b$$\n",
    "\n",
    "就是一个仿射函数。\n",
    "\n",
    "仿射函数有一个非常重要的性质，那就是它既凹又凸，准确来讲在凹凸函数的那个不等式中，仿射函数是可以取等号的【可以先理解为仿射函数几何图像就是一条直线，那直线肯定是取等号的】:\n",
    "\n",
    "$$f(\\theta x+(1-\\theta) y)=\\theta f(x)+(1-\\theta) f(y)$$\n",
    "\n",
    "**凸优化**\n",
    "\n",
    "优化问题的基本形式:\n",
    "\n",
    "$$\\min_{x \\in \\mathbb{R}^{n}} f(x)$$\n",
    "$$s.t \\quad c_{i}(x)\\leq 0, i \\in[1, k]$$\n",
    "$$\\quad \\quad h_{j}(x)=0, j \\in[1, l]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而所谓的凸优化，是满足一些特定条件的优化问题，它要求:\n",
    "\n",
    "1. $f(x)$是凸函数\n",
    "2. $c_i(x)$是凸函数\n",
    "3. $h_j(x)$是仿射函数\n",
    "\n",
    "也就是:\n",
    "\n",
    "$$\\min_{x \\in \\mathbb{R}^{n}} f(x)$$\n",
    "$$s.t \\quad c_{i}(x)\\leq 0, i \\in[1, k]$$\n",
    "$$\\quad \\quad a_j(x)=b_j, j \\in[1, l]$$\n",
    "\n",
    "凸优化有一个重要的性质：任意位置的局部最优解同时也是全局最优解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、从广义拉格朗日函数到拉格朗日对偶函数\n",
    "\n",
    "原问题 (Primal Problem):\n",
    "\n",
    "$$\\min_{x \\in \\mathbb{R}^{n}} f(x)$$\n",
    "$$s.t \\quad c_{i}(x)\\leq 0, i \\in[1, k]$$\n",
    "$$\\quad \\quad h_{j}(x)=0, j \\in[1, l]$$\n",
    "\n",
    "首先我们做两个约定:\n",
    "\n",
    "- 我们不假定原函数f的凹凸性，也就是f可以是非凸非凹函数\n",
    "- 记问题的定义域$D=(\\operatorname{dom} f) \\cap\\left(\\bigcap_{i=1}^{k} c_{i}\\right) \\cap\\left(\\bigcap_{i=1}^{l} h_{i}\\right)$\n",
    "- D!=∅\n",
    "- 我们约定最终求出来的最优结果用$p^*$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、什么是对偶\n",
    "\n",
    "对于原问题我们通常用拉格朗日对偶的方式来求解。啥是对偶？对偶说白了就是实质相同但从不同角度提出不同提法的一对问题。有时候原问题 (Primal Problem) 不太好解，但是对偶问题 (Dual Problem) 却很好解，我们就可以通过求解对偶问题来迂回地解答原问题。\n",
    "\n",
    "在这里我们用的是拉格朗日对偶的方法来解决，既然我们说用对偶的方法的原因在于原问题不好解，那么这里也是如此吗？\n",
    "\n",
    "当然了。\n",
    "\n",
    "首先我们来看看原问题有什么难的地方:\n",
    "\n",
    "1. 约束条件太多\n",
    "\n",
    "   很显然约束越多，问题就越难解决，原问题中总共有$k+l$个约束，相当麻烦\n",
    "\n",
    "\n",
    "2. 原问题凹凸性不明确\n",
    "\n",
    "   之前我们说过，“不假定原函数f的凹凸性”，这就意味着我们无法将凸优化的方法应用在原问题中\n",
    "   \n",
    "那么它的拉格朗日对偶问题有什么优点呢？\n",
    "\n",
    "1. 只有一个约束\n",
    "\n",
    "\n",
    "2. 拉格朗日对偶问题一定是凹的\n",
    "\n",
    "这里先做一个感性的认识，细节方面接下来慢慢说。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、广义 Lagrange 函数\n",
    "\n",
    "早前我们说过，对于等式约束问题可以用构建拉格朗日函数的方法来求解。这里也一样，我们可以为原问题构建一个广义拉格朗日函数$\\mathcal{L}$:\n",
    "\n",
    "$$\\mathcal{L}: \\mathbb{R}^{n} \\times \\mathbb{R}^{\\mathbb{k}} \\times \\mathbb{R}^{l} \\rightarrow R$$\n",
    "$$\\mathcal{L}(x, \\lambda, \\mu)=f(x)+\\sum_{i=1}^{k} \\lambda_{i} c_{i}(x)+\\sum_{j=1}^{l} \\mu_{j} h_{j}(x)$$\n",
    "$$\\vec{x} \\in \\mathbb{R}^{n}, \\vec{\\lambda} \\in \\mathbb{R}^{\\mathbb{k}}, \\vec{\\mu} \\in \\mathbb{R}^{l}$$\n",
    "\n",
    "$\\vec{\\lambda}$和$\\vec{\\mu}$被称为拉格朗日乘子向量。\n",
    "\n",
    "有了这个广义拉格朗日函数，现在我们分别可以定义另外对偶函数g。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、Lagrange 对偶函数g\n",
    "\n",
    "我们可以根据$\\mathcal{L}$定义一个拉格朗日对偶函数(Lagrange Dual Function)$g(\\lambda, \\mu)$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "g(\\lambda, \\mu)&=\\inf _{x \\in D} \\mathcal{L}(x, \\lambda, \\mu)\\\\\n",
    "&=\\inf _{x \\in D}\\left(f(x)+\\sum_{i=1}^{k} \\lambda_{i} c_{i}(x)+\\sum_{j=1}^{l} \\mu_{j} h_{j}(x)\\right)\\\\\n",
    "\\lambda \\geq 0 &\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "这个对偶函数g有一个非常重要的性质：它一定是一个凹函数，我们可以证明一下。\n",
    "\n",
    "首先我们明确一个凹函数具有性质:\n",
    "\n",
    "$$f(\\theta x+(1-\\theta) y) \\geqslant \\theta f(x)+(1-\\theta) f(y)$$\n",
    "\n",
    "要证明g是一个凹函数就是要证明它满足这个不等式。\n",
    "\n",
    "**第一步**\n",
    "\n",
    "我们首先记:\n",
    "\n",
    "$$g(\\lambda, \\mu)=\\inf _{x \\in D}\\left\\{\\mathcal{L}\\left(x_{1}, \\lambda, \\mu\\right), \\mathcal{L}\\left(x_{2}, \\lambda, \\mu\\right), \\cdots, \\mathcal{L}\\left(x_{n}, \\lambda, \\mu\\right)\\right\\}, n \\rightarrow+\\infty$$\n",
    "\n",
    "这个好理解，就是把连续的函数离散成无限个点的集合，这样就可以把g看作一个逐点求下界的无穷集合。\n",
    "\n",
    "**第二步**\n",
    "\n",
    "简记:\n",
    "\n",
    "$$\\gamma=(\\lambda, \\mu), g(\\gamma)=g(\\lambda, \\mu)$$\n",
    "\n",
    "这个主要是为了一会推导的时候方便写。\n",
    "\n",
    "**第三步**\n",
    "\n",
    "证明过程如下:\n",
    "$$\n",
    "\\begin{align}\n",
    "g\\left(\\theta \\gamma_{1}+(1-\\theta) \\gamma_{2}\\right)&=\\inf \\left\\{\\mathcal{L}\\left(x_{1}, \\theta \\gamma_{1}+(1-\\theta) \\gamma_{2}\\right), \\mathcal{L}\\left(x_{2}, \\theta \\gamma_{1}+(1-\\theta) \\gamma_{2}\\right), \\cdots, \\mathcal{L}\\left(x_{n}, \\theta \\gamma_{1}+(1-\\theta) \\gamma_{2}\\right)\\right\\}\\\\\n",
    "&\\geqslant \\inf \\left\\{\\theta \\mathcal{L}\\left(x_{1}, \\gamma_{1}\\right)+(1-\\theta) \\mathcal{L}\\left(x_{1}, \\gamma_{2}\\right), \\cdots, \\theta \\mathcal{L}\\left(x_{n}, \\gamma_{1}\\right)+(1-\\theta) \\mathcal{L}\\left(x_{n}, \\gamma_{2}\\right)\\right\\}\\\\\n",
    "&\\geqslant \\theta \\inf \\left\\{\\mathcal{L}\\left(x_{1}, \\gamma_{1}\\right), \\mathcal{L}\\left(x_{2}, \\gamma_{1}\\right), \\cdots, \\mathcal{L}\\left(x_{n}, \\gamma_{1}\\right)\\right\\}+(1-\\theta) \\inf \\left\\{\\mathcal{L}\\left(x_{1}, \\gamma_{2}\\right), \\mathcal{L}\\left(x_{2}, \\gamma_{2}\\right), \\cdots, \\mathcal{L}\\left(x_{n}, \\gamma_{2}\\right)\\right\\}\\\\\n",
    "&=\\theta g\\left(\\gamma_{1}\\right)+(1-\\theta) g\\left(\\gamma_{2}\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解释过程：\n",
    "\n",
    "第一行到第二行是因为$L(x_i, \\gamma)$中的x的值已固定，所以$f_{i}(x), i=0,1,2, \\cdots, m$ 和 $h_{i}(x), i=0,1,2, \\cdots, p$\n",
    "\n",
    "都应该看做常数，所以此时的$L(x_i, \\gamma)$是$\\gamma$的仿射函数，而仿射函数是既凸且凹的，对第一行右边中的每一个拉格朗日函数都运用其凹性，就可以得到第二行。\n",
    "\n",
    "而从第二行到第三行运用的是一个简单的数学原理：\n",
    "\n",
    "设有两个实数集合a和b:\n",
    "\n",
    "$$a=\\left\\{a_{1}, a_{2}, \\cdots, a_{n}\\right\\}$$\n",
    "\n",
    "$$b=\\left\\{b_{1}, b_{2}, \\cdots, b_{n}\\right\\}$$\n",
    "\n",
    "则对于所有的i、j有：\n",
    "\n",
    "$$\\min \\left\\{a_{i}+b_{j}\\right\\} \\geq \\min \\{a\\}+\\min \\{b\\}, \\quad i, j \\in N^{+}$$\n",
    "\n",
    "最后通过图像来解释:\n",
    "\n",
    "<img src=\"imgs/duality.png\" width=\"200\"/>\n",
    "\n",
    "上图中，每条直线表示的是一个$L(x_i, \\gamma)$假想有一条平行于上图中y轴方向的直线，这条直线沿着x轴方向平移，这条直线与上图中所有的$L(x_i, \\gamma)$相交，这些交点的最小值（y轴方向的值，因为y轴方向对应于$L(x_i, \\gamma)$的值，x轴方向对应于每一个$x_i$）就是$g(\\gamma)$，也就是（第一步公式）要表达的意思。\n",
    "\n",
    "由于这条直线每到一处，就对应于一个$x_i$从而逐点逐点地获得$g(\\gamma)$，所以就称对偶函数是一族关于$\\gamma$的仿射函数的逐点下确界。\n",
    "\n",
    "**总结: 不管原函数f的凹凸性，它的对偶函数g一定是凹函数。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、对偶函数与原函数的关系\n",
    "\n",
    "我们之所以需要这么一个对偶函数是因为g有一个非常重要的作用，什么意思呢？其实这是 Dual Function 一个很重要的性质:\n",
    "\n",
    "$$\\forall \\lambda \\geqslant 0 \\Rightarrow g(\\lambda, \\mu) \\leqslant p^{*}$$\n",
    "\n",
    "换而言之，只要λ不小于0，g的值永远不会超过$p^*$\n",
    "\n",
    "要证明这个定理并不难，我们首先假设$\\hat x \\in D$是原问题的一个可行解:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\because c_{i}(\\hat{x}) \\leqslant 0, h_{i}(\\hat{x})=0\\\\\n",
    "&\\therefore \\lambda_{i} c_{i} \\leqslant 0, \\mu_{i} h_{i}=0\\\\\n",
    "&\\therefore \\mathcal{L}(\\hat{x}, \\lambda, \\mu)=f(x)+\\sum_{i=1}^{k} \\lambda_{i} c_{i}(\\hat{x})+\\sum_{j=1}^{l} \\mu_{j}h_{j}(\\hat{x}) \\leqslant f(x)\\\\\n",
    "&Meanwhile\\ g(\\lambda, \\mu)=\\inf \\mathcal{L}, \\quad p^{*}=\\min f\\\\\n",
    "&\\therefore g(\\lambda, \\mu) \\leqslant \\mathcal{L} \\leqslant p^{*}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "这给了我们一个重要的启示，无论如何，$p^*$都不会小于$\\max{g(\\lambda, \\mu)}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、从原问题到拉格朗日对偶问题\n",
    "\n",
    "在此之前，我们讲了原问题，讲了广义拉格朗日函数和拉格朗日对偶函数，又讲了这两个之间的关系。那么这有什么用呢？\n",
    "\n",
    "用处当然很大啦！现在我们不妨这么一想，既然Lagrange对偶函数给出了最优解$p^*$的下界，那么从拉格朗日对偶函数中可以得到的最佳下界是什么呢?\n",
    "  \n",
    "我们来捋一捋:\n",
    "\n",
    "1. 首先我们明确一件事，我们的目的是找到最优解$p^*$\n",
    "\n",
    "2. 有时候$p^*$其实并不一定能解出来，这种情况下，我们希望可以给出一个尽可能地逼近$p^*$的值\n",
    "\n",
    "3. 既然我们已经知道了g可以给出下界，那么哪个值能够尽可能逼近呢？\n",
    "\n",
    "4. 答案是:$\\max g(\\lambda, \\mu)\\ (s.t\\ λ⩾0)$\n",
    "\n",
    "<img src=\"imgs/duality_max.png\" width=\"400\"/>\n",
    "\n",
    "明白了这一点，我们终于可以介绍拉格朗日对偶问题了。\n",
    "\n",
    "首先再次回顾一下原问题。\n",
    "\n",
    "$$Primal Problem$$\n",
    "\n",
    "$$\\min_{x \\in \\mathbb{R}^{n}} f(x)$$\n",
    "$$s.t \\quad c_{i}(x)\\leq 0, i \\in[1, k]$$\n",
    "$$\\quad \\quad h_{j}(x)=0, j \\in[1, l]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后隆重介绍对偶问题的形式。\n",
    "\n",
    "$$Lagrange Dual Problem$$\n",
    "\n",
    "$$\\max _{\\lambda, \\mu} g(\\lambda, \\mu)=\\max _{\\lambda, \\mu} \\inf _{x \\in D} \\mathcal{L}(x, \\lambda, \\mu)$$\n",
    "$$s.t \\quad \\lambda_{i} \\geqslant 0, i=1,2, \\ldots, k$$\n",
    "\n",
    "参考上面那幅图，其实这个所谓的对偶问题在干什么已经很清楚了。我们把原问题的结果设为$p^*$，而对偶问题的结果记为$d^*$。\n",
    "\n",
    "\n",
    "现在回顾一下之前说的求解对偶问题的好处，我们再来看看为什么需要拉格朗日对偶。\n",
    "\n",
    "首先对于原问题:\n",
    "\n",
    "1. 原问题的约束太多了，又是等式又是不等式\n",
    "2. 原问题不一定是一个凸优化问题，所以即便找到了貌似是$p^*$的点，也很可能不过是个局部最优点。\n",
    "\n",
    "那 Lagrange 对偶问题就好一些吗？还真是，我们来看看:\n",
    "\n",
    "1. 约束少了，这是很明显的，少了$l$个，而且剩下的k个约束也比原来的简单一些\n",
    "2. 最最重要的，对偶问题一定是一个凸优化问题，所以很多凸优化的手段全可以用上了\n",
    "\n",
    "总结一下就是:\n",
    "\n",
    "我们希望求$p^*$，但是$p^*$实在不好求，所以退而求其次去求$d^*$，这个就好求多了。\n",
    "\n",
    "并且由于$d^* \\leqslant p^*$，我们在求出了$d^*$后即便不能得到$p^*$，也可以得到$p^*$的下界；而在一些非常理想的情况下，$d^* = p^*$。\n",
    "\n",
    "$d^* = p^*$如果真能这样那简直就是天堂了，显然一般情况下这两个是不同的，但是在满足某些特殊条件时，这个等式就可以成立了。具体这些条件是什么，我们在接下来的几节里再来谈谈。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五、弱对偶与强对偶\n",
    "\n",
    "所谓强弱对偶，指的是 Lagrange 对偶问题的一种性质。\n",
    "\n",
    "## 1、弱对偶\n",
    "\n",
    "弱对偶就是$𝑑^∗<𝑝^∗$\n",
    "\n",
    "## 2、强对偶\n",
    "\n",
    "强对偶就是$𝑑^∗=𝑝^∗$\n",
    "\n",
    "之所以称之为“强”对偶，正是因为这种性质相对于“弱”对偶而言对我们的意义更加重大。很显然，当我们待求解的问题是强对偶的话，那就意味着我们通过对偶问题求的的解就不再仅仅是原问题解的一个下界了，而是$𝑝^∗$本身。用人话来讲就是：\n",
    "\n",
    "**如果满足强对偶，那只要我们求出了$d^*$，我们就知道了$𝑝^∗$的值**\n",
    "\n",
    "显然，强对偶并不是什么时候都成立的，必须要满足一定的条件才会有强对偶这种东西。\n",
    "\n",
    "下一节，我们着重讲解这些条件是什么 (充分条件、必要条件)。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 六、关于强对偶和最优的一些条件\n",
    "\n",
    "首先要明确一件事情：使满足强对偶的条件有很多种，我们这里只介绍最基本的。\n",
    "\n",
    "## 1、Convex + Slater\n",
    "\n",
    "如果:\n",
    "\n",
    "- 原问题是凸优化\n",
    "\n",
    "- 满足 Slater 条件\n",
    "\n",
    "则一定满足强对偶\n",
    "\n",
    "注: 这是强对偶的一个充分条件\n",
    "\n",
    "下面具体解释一下含义。\n",
    "\n",
    "如果原问题是凸问题，必须满足：\n",
    "\n",
    "1. $f(x)$是凸函数\n",
    "2. $c_i(x)$是凸函数\n",
    "3. $h_j(x)$是仿射函数\n",
    "\n",
    "满足Slater条件：\n",
    "\n",
    "$$\\exists x \\in D$$\n",
    "\n",
    "$$c_{i}(x)<0, i \\in[1, k]$$\n",
    "\n",
    "$$Ax=b$$\n",
    "\n",
    "其中$Ax=b$是把$a_j x=b_j$合起来写的写法，我们的主要关注点在$c_i$上。我们把满足该条件的点称为是严格可行的，因为不等式约束要求严格成立。\n",
    "\n",
    "之所以称上述的 Slater 条件是严格的，是因为 Slater 还有一个弱化的版本。\n",
    "\n",
    "$$c_{i}(x)是仿射函数,i=[1, p] \\& p \\leqslant k$$\n",
    "\n",
    "$$则弱化的Slater条件为:$$\n",
    "\n",
    "$$\\exists x \\in D$ $$\n",
    "\n",
    "$$c_{i}(x) \\leqslant 0, i \\in[1, p]$$\n",
    "\n",
    "$$c_{i}(x)<0, i \\in[p+1, k]$$\n",
    "\n",
    "$$Ax=b$$\n",
    "\n",
    "任意满足:\n",
    "\n",
    "1. 凸优化\n",
    "2. 强或弱 Slater 条件\n",
    "\n",
    "的优化问题同样满足强对偶性 (充分条件)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、KKT 条件\n",
    "\n",
    ">对于无约束最优化问题，其搜索空间是无界的，只要确定了搜索方向和步长因子，便可以在一轮或几轮迭代之后找到最优解或近似最有解。这里举个不太恰当的例子，无约束最优化如同在浩瀚的宇宙中寻找体积最大的星球，你按照一定的策略去找，不用担心越界。\n",
    ">\\\n",
    ">而约束的优化问题就不同了，在寻找最优解的过程中始终要在某一个约束范围空间内进行。还是以上述例子说明，约束最优化如同在浩瀚的宇宙中寻找体积最大的星球，你按照一定的策略去找，但是不能离开银河系。KKT条件正是这类最优化问题的最优解必须要满足的条件，言外之意便是只要是最优解，必然满足这个条件，反之则不然；但对于凸问题，确是充分必要条件，这一点很重要，很多问题是凸的，这就为问题求解带来很大的便利性。\n",
    "\n",
    "有必要明确一些很重要的点。\n",
    "\n",
    "首先是 KKT 条件实际上应该分为两种情况讨论:\n",
    "\n",
    "- Case 1: 原问题为非凸问题情况下的 KKT\n",
    "\n",
    "- Case 2: 原问题为凸问题情况下的 KKT\n",
    "\n",
    "为什么要分两点来讨论？因为在两种情况下，KKT 条件作为一个“条件”的充分性和必要性是不同的，自然用法也不同。\n",
    "\n",
    "再有一个问题是，无论哪种情况，KKT 都是着眼于“最优解”这个议题进行讨论的。\n",
    "\n",
    "下面分两种情况讨论。\n",
    "\n",
    "**非凸问题下的 KKT**\n",
    "\n",
    "当原问题并非凸优化(或者不清楚、不关心是不是凸优化)时，KKT 条件是一种用来描述强对偶情况下最优解性质的条件\n",
    "\n",
    "换而言之，若强对偶性质成立，那么满足最优解的点一定满足 KKT 条件；KKT 条件是强对偶一个必要条件，但无法作为充分条件来使用\n",
    "\n",
    "我们首先给出 KKT 条件的具体数学描述，然后逐行解释。\n",
    "\n",
    "假设:\n",
    "\n",
    "1. 原问题中的函数均可微\n",
    "2. 强对偶成立\n",
    "\n",
    "$x_*$和$(\\lambda^*, \\mu^*)$分别为原问题和对偶问题的某对最优解\n",
    "\n",
    "则:\n",
    "\n",
    "$$\\begin{array}\n",
    "{lr}c_{i}\\left(x^{*}\\right) \\leqslant 0 & i=1, \\ldots, k \\\\\n",
    "h_{i}\\left(x^{*}\\right)=0 & i=1, \\ldots, l \\\\\n",
    "\\lambda_{i}^{*} \\geqslant 0 & i=1, \\ldots, k \\\\\n",
    "\\lambda_{i}^{*} c_{i}\\left(x^{*}\\right)=0 & i=1, \\ldots, k \\\\\n",
    "\\nabla f\\left(x^{*}\\right)+\\sum_{i=1}^{k} \\lambda_{i}^{*} \\nabla c_{i}\\left(x^{*}\\right)+\\sum_{i=1}^{l} \\mu_{i}^{*} \\nabla h_{i}\\left(x^{*}\\right)=0\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这就是 KKT 条件了，第一行和第二行是原问题的约束，必须遵守；第三行则是弱对偶的必要条件。最后一行，我们知道，既然$x^*$是最优点，那么理所当然的，原问题$\\mathcal{L}$关于$x^*$的导数必须等于0。\n",
    "\n",
    "现在难点主要在第四行，其实第四行的不等式是一个被称为“互补松弛条件”的东西。我们做一个简单的证明。\n",
    "\n",
    "首先我们知道\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f\\left(x^{*}\\right)&=g\\left(\\lambda^{*}, \\mu^{*}\\right) \\\\\n",
    "&=\\inf _{x} \\mathcal{L}\\left(x^{*}, \\lambda^{*}, \\mu^{*}\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "所以有:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f\\left(x^{*}\\right)& \\leq \\mathcal{L}\\left(x^{*}, \\lambda^{*}, \\mu^{*}\\right) \\\\\n",
    "&=f\\left(x^{*}\\right)+\\sum_{i=1}^{k} \\lambda_{i}^{*} c_{i}\\left(x^{*}\\right)+\\sum_{i=1}^{l} \\mu_{i}^{*} h_{i}\\left(x^{*}\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "同时我们知道，$\\lambda \\geq 0$ 且 $c_i(x) \\leq 0$，而$h_i=0$，所以有：\n",
    "\n",
    "$$f\\left(x^{*}\\right)+\\sum_{i=1}^{k} \\lambda_{i}^{*} c_{i}\\left(x^{*}\\right)+\\sum_{i=1}^{l} \\mu_{i}^{*} \\leq f(x^*)$$\n",
    "\n",
    "联立上面几个式子，有:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f\\left(x^{*}\\right)&=g\\left(\\lambda^{*}, \\mu^{*}\\right) \\\\\n",
    "&=\\inf_x f\\left(x^{*}\\right)+\\sum_{i=1}^{k} \\lambda_{i}^{*} c_{i}\\left(x^{*}\\right)+\\sum_{i=1}^{l} \\mu_{i}^{*}\\\\\n",
    "&=f\\left(x^{*}\\right)+\\sum_{i=1}^{k} \\lambda_{i}^{*} c_{i}\\left(x^{*}\\right)+\\sum_{i=1}^{l} \\mu_{i}^{*}\\\\\n",
    "&=f\\left(x^{*}\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "注意到第二行和第三行想等，而$\\lambda_i c_i \\leq 0$，所以为了让等式成立，必然有:\n",
    "\n",
    "$$\\lambda_i c_i(x) = 0$$\n",
    "\n",
    "这被称为互补松弛条件。\n",
    "\n",
    "把这几个条件一股脑叠加在一起，就构成了 KKT 条件。对于目标函数和约束函数可微的优化问题，如果强对偶成立，则任意一对原问题的最优解和对偶问题的最优解满足 KKT 条件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**凸问题下的 KKT**\n",
    "\n",
    "当原问题为凸优化时，KKT 条件在非凸的基础上有多了找到最优点的功能\n",
    "在这种情况下，那么满足 KKT 条件的点一定是原问题和对偶问题的最优解；KKT 条件成了强对偶和最优解的充要条件\n",
    "\n",
    "也就是说:\n",
    "\n",
    "1. 若原问题是Convex的\n",
    "2. $\\exists x^*, \\lambda^*, \\mu^*$满足:\n",
    "\n",
    "$$\\begin{array}\n",
    "{lr}c_{i}\\left(x^{*}\\right) \\leqslant 0 & i=1, \\ldots, k \\\\\n",
    "h_{i}\\left(x^{*}\\right)=0 & i=1, \\ldots, l \\\\\n",
    "\\lambda_{i}^{*} \\geqslant 0 & i=1, \\ldots, k \\\\\n",
    "\\lambda_{i}^{*} c_{i}\\left(x^{*}\\right)=0 & i=1, \\ldots, k \\\\\n",
    "\\nabla f\\left(x^{*}\\right)+\\sum_{i=1}^{k} \\lambda_{i}^{*} \\nabla c_{i}\\left(x^{*}\\right)+\\sum_{i=1}^{l} \\mu_{i}^{*} \\nabla h_{i}\\left(x^{*}\\right)=0\n",
    "\\end{array}$$\n",
    "\n",
    "那么$x^*$和$(\\lambda^*, \\mu^*)$分别是原问题和对偶问题的最优解，且最优对偶间隙为0，强对偶性满足。\n",
    "\n",
    "**几种条件之间的关系的总结**\n",
    "\n",
    "1. 对于任意问题\n",
    "\n",
    "强对偶 + 最优解 ⇒ KKT条件\n",
    "\n",
    "2. 对于 Convex + 可微 的问题\n",
    "\n",
    "KKT 条件 ⇒ 强对偶 + 最优解\n",
    "\n",
    "3. Convex + Slater ⇒ 强对偶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 七、总结\n",
    "\n",
    "**原问题：**带约束问题不好求解\n",
    "\n",
    "$$\\min_{x \\in \\mathbb{R}^{n}} f(x)$$\n",
    "$$s.t \\quad c_{i}(x)\\leq 0, i \\in[1, k]$$\n",
    "$$\\quad \\quad h_{j}(x)=0, j \\in[1, l]$$\n",
    "\n",
    "\n",
    "**拉格朗日函数：**将带约束问题变成无约束问题，但是仍然不好解\n",
    "\n",
    "$$\\mathcal{L}: \\mathbb{R}^{n} \\times \\mathbb{R}^{\\mathbb{k}} \\times \\mathbb{R}^{l} \\rightarrow R$$\n",
    "$$\\mathcal{L}(x, \\lambda, \\mu)=f(x)+\\sum_{i=1}^{k} \\lambda_{i} c_{i}(x)+\\sum_{j=1}^{l} \\mu_{j} h_{j}(x)$$\n",
    "$$\\vec{x} \\in \\mathbb{R}^{n}, \\vec{\\lambda} \\in \\mathbb{R}^{\\mathbb{k}}, \\vec{\\mu} \\in \\mathbb{R}^{l}$$\n",
    "\n",
    "简化为：\n",
    "\n",
    "<font color=\"red\">$$\\min_x\\max_{\\lambda, \\mu}\\mathcal{L}(x, \\lambda, \\mu)$$</font>\n",
    "\n",
    "**拉格朗日对偶函数：**拉格朗日函数不好解，我们看看它的对偶问题（对偶函数一定是凹函数），对偶问题就是能够得出和原问题相同解的问题\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "g(\\lambda, \\mu)&=\\inf _{x \\in D} \\mathcal{L}(x, \\lambda, \\mu)\\\\\n",
    "&=\\inf _{x \\in D}\\left(f(x)+\\sum_{i=1}^{k} \\lambda_{i} c_{i}(x)+\\sum_{j=1}^{l} \\mu_{j} h_{j}(x)\\right)\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\\max _{\\lambda, \\mu} g(\\lambda, \\mu)=\\max _{\\lambda, \\mu} \\inf _{x \\in D} \\mathcal{L}(x, \\lambda, \\mu)$$\n",
    "$$s.t \\quad \\lambda_{i} \\geqslant 0, i=1,2, \\ldots, k$$\n",
    "\n",
    "<img src=\"imgs/duality_max.png\" width=\"400\"/>\n",
    "$$p^*是原问题的解$$\n",
    "\n",
    "简化为：\n",
    "\n",
    "<font color=\"red\">$$\\max_{\\lambda, \\mu}\\min_x\\mathcal{L}(x, \\lambda, \\mu)$$</font>\n",
    "\n",
    "**KKT约束：**因为对偶问题可以通过不断迭代找到接近于原问题的解，但是不一定等于，所以我们加上kkt条件约束就能保证等于\n",
    "\n",
    "kkt约束将上图中的$p^*$和$d^*$的距离消除，保证$p^* = d^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
