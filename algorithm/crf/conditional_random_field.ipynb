{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 条件随机场\n",
    "\n",
    "    序列标注模型条件随机场，这种模型与感知机同属结构化学习大家族，但性能比感知机还要强大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、机器学习的模型谱系\n",
    "\n",
    "<img src=\"./imgs/machine_learning_model.png\" alt=\"机器学习的模型谱系\" width=\"800\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    【假设我们有训练数据(X,Y)，X是属性集合，Y是类别标记。这时来了一个新的样本x，我们想要预测它的类别y。\n",
    "    我们最终的目的是求得最大的条件概率P(y|x)作为新样本的分类。】\n",
    "    \n",
    "    根据建模的究竟是联合概率（同时发生的概率）分布P(x,y)还是条件概率分布P(y|x)。派生出生成式模型与判别式模型，这两个模型最终算的都是\n",
    "    P(y|x)\n",
    "\n",
    "### 1、生成式模型\n",
    "\n",
    "    【一般会对每一个类建立一个模型，有多少个类别，就建立多少个模型。比如说类别标签有｛猫，狗，猪｝，那首先根据猫的特征学习出一个猫的模型，再根据狗的特征学习出狗的模型，之后分别计算新样本 x 跟三个类别的联合概率 P(x,y) ，然后根据贝叶斯公式计算出P(y|x)】\n",
    "\n",
    "    生成式模型：模拟数据的生成过程，两类随机变量存在因果先后关系，先有因素 y，后有结果 x，这种因果关系由联合分布模拟：\n",
    "\n",
    "$$P(x,y) = P(y)P(x|y)$$\n",
    "\n",
    "    通过联合分布 P(x,y)，生成式模型其实间接建模了 P(x)：\n",
    "    \n",
    "$$P(x) = \\sum_{y \\in Y}P(x,y)$$\n",
    "\n",
    "    然后依据贝叶斯公式可以得到P(y|x):\n",
    "    \n",
    "$$P(y|x) = \\frac{P(x,y)}{P(x)}$$\n",
    "\n",
    "    这里有两个缺陷:\n",
    "\n",
    "    1、P(x) 很难准确估计，因为特征之间并非相互独立，而是存在错综复杂的依赖关系。\n",
    "    2、P(x) 在分类中也没有直接作用。\n",
    "\n",
    "    为了克服这两个问题，判别式模型出现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、判别式模型\n",
    "\n",
    "    【根据训练数据得到分类函数和分界面，比如说根据SVM模型得到一个分界面，然后直接计算条件概率 P(y|x) ，我们将最大的 P(y|x) 作为新样本的分类。判别式模型是对条件概率建模，学习不同类别之间的最优边界，无法反映训练数据本身的特性，能力有限，其只能告诉我们分类的类别。】\n",
    "\n",
    "    判别式模型直接跳过了 P(x)，直接对条件概率 P(y|x) 建模。不管 x 内部存在多复杂的关系，也不影响判别式模型对 y 的判断，于是就能够放心大胆的利用各种各样丰富的、有关联的特征。 所以我们会看到感知机分词的准确率高于隐马尔可夫模型。\n",
    "\n",
    "$$P(y|x) = \\frac{exp(score(x,y))}{\\sum_{x,y}exp(score(x,y))}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、两个模型总结\n",
    "\n",
    "不管是生成式模型还是判别式模型，它们最终的判断依据都是条件概率P(y|x)，但是生成式模型先计算了联合概率P(x,y)，再由贝叶斯公式计算得到条件概率。因此，生成式模型可以体现更多数据本身的分布信息，其普适性更广。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、举例说明\n",
    "\n",
    "    假设要对猫和狗进行区分：\n",
    "    \n",
    "    判别式模型：用判别式模型的方法是从历史数据中学习到模型，然后通过提取该动物的特征来预测出是狗的概率，是猫的概率。\n",
    "\n",
    "    生成式模型：是根据狗的特征首先学习出一个狗的模型，然后根据猫的特征学习出一个猫的模型，然后从这个动物中提取特征，放到狗模型中看概率是多少，再放到猫模型中看概率是多少，哪个大就是哪个。\n",
    "    \n",
    "### 5、数据计算过程样例\n",
    "\n",
    "    假设现在有一个分类问题，X是特征，Y是类标记。用判别式模型学习一个条件概率分布P(y|x)，用生成式模型学习一个联合概率分布 P(x,y) 。用一个简单的例子来说明这个问题。假设X就是两个特征（1或2），Y有两类（0或1），有如下训练样本（1，0）、（1，0）、（1，1）、（2，1）。\n",
    "\n",
    "    则学习到的条件概率分布（判别式模型）如下：\n",
    "    \n",
    "| | 0 | 1 |\n",
    "|-|-|-|\n",
    "|1|2/3|1/3|\n",
    "|2|0|1|\n",
    "\n",
    "\n",
    "    而学习到的联合概率分布（生成式模型）如下：\n",
    "| | 0 | 1 |\n",
    "|-|-|-|\n",
    "|1|1/2|1/4|\n",
    "|2|0|1/4|\n",
    "\n",
    "    在实际分类问题中，判别式模型可以直接用来判断特征的类别情况；而生成式模型需要加上贝叶斯公式，然后应用到分类中。但是，生成式模型的概率分布可以有其他应用，就是说生成式模型更一般更普适。不过判别式模型更直接，更简单。两种方法目前交叉较多。由生成式模型可以得到判别式模型，但由判别式模型得不到生成式模型。\n",
    "\n",
    "### 6、用图说明区别\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
